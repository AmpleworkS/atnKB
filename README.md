# ğŸ§  Customer Insights Chatbot  

An **AI-powered Customer Insights Chatbot** that combines **structured SQL queries (PostgreSQL)** with **semantic search (Pinecone)** and **LLMs (OpenAI)** to provide customer insights in natural language.  

This chatbot enables businesses to query customer data, analyze pain points, and retrieve actionable insights seamlessly through a simple **Flask-based web interface**.  

---

## ğŸš€ Features  
ğŸ”¹ **Hybrid Querying:** Structured (Postgres) + Semantic (Pinecone).  
ğŸ”¹ **Natural Language Interface:** Powered by OpenAI GPT models.  
ğŸ”¹ **Customer Insights:** Retrieve pain points, objections, goals, and structured data.  
ğŸ”¹ **Web UI:** Clean chat interface built with HTML, CSS, and JS.  
ğŸ”¹ **Scalable:** Can be deployed on Railway, Render, or any Flask-supported hosting.  

---

## ğŸ› ï¸ Tech Stack  
- **Backend:** Flask  
- **Database:** PostgreSQL  
- **Vector DB:** Pinecone  
- **LLM Provider:** OpenAI GPT (GPT-4o by default)  
- **Embeddings:** OpenAI `text-embedding-3-large`  
- **Frontend:** HTML, CSS, JavaScript  
- **Environment Management:** `python-dotenv`  

---

## ğŸ“‚ Project Structure  
project/
â”‚â”€â”€ app.py # Main Flask application
â”‚â”€â”€ llm_utils.py # OpenAI LLM wrapper
â”‚â”€â”€ pinecone_utils.py # Pinecone search integration
â”‚â”€â”€ postgres_utils.py # PostgreSQL query runner
â”‚â”€â”€ ui_utils.py # UI helpers
â”‚â”€â”€ templates/
â”‚ â””â”€â”€ chat.html # Frontend chat interface
â”‚â”€â”€ static/
â”‚ â”œâ”€â”€ style.css # CSS for styling
â”‚ â””â”€â”€ script.js # JS for handling chat interactions
â”‚â”€â”€ .env # Environment variables
â”‚â”€â”€ requirements.txt # Dependencies
â”‚â”€â”€ README.md # Documentation

---

## âš™ï¸ Setup Instructions  

1. Clone the Repository  

git clone <your-repo-url>
cd <repo-name>

2. Install Dependencies

pip install -r requirements.txt

3. Configure Environment Variables

Create a .env file in the root directory:
env

OPENAI_API_KEY = <your_openai_api_key>
PINECONE_API_KEY= <your_pinecone_api_key>
PINECONE_INDEX = <your_index_name>
PINECONE_NAMESPACE = <your_namespace_name>
DB_NAME= <your_db_name>
DB_USER= <your_db_user_name>
DB_PASSWORD= <your_db_password>
DB_HOST= <your_db_host>
DB_PORT= <your_db_port>

4. Run the Application
python app.py
Now visit ğŸ‘‰ http://localhost:5000


## ğŸ” How It Works
User sends a query in chat.

LLM decides whether to use:

Postgres Tool â†’ for structured queries.

Pinecone Tool â†’ for semantic insights.

Tool results are added back into the conversation.

LLM returns a human-friendly response.

UI displays the chatbotâ€™s answer.

## ğŸ§ª Example Queries
â€œList all customers interested in the Diamond package.â€ â†’ (Postgres)

â€œWhat are the top 3 pain points of customers in the USA?â€ â†’ (Pinecone)

â€œHow many customers are in the Gold package?â€ â†’ (Postgres)


## âœ¨ Acknowledgments
OpenAI for LLM APIs

Pinecone for vector database

PostgreSQL for relational database

Flask for backend framework